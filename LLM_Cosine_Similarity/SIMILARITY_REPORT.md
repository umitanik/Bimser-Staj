# ğŸ” Embedding Modelleri Benzerlik Analizi Raporu

Bu rapor, 8 farklÄ± embedding modelinin **TÃ¼rkÃ§e-Ä°ngilizce kurumsal terimler** Ã¼zerindeki performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±ran kapsamlÄ± bir analiz sunmaktadÄ±r.

## ğŸ“‹ Proje Ã–zeti

Bu proje, farklÄ± embedding modellerinin **cosine similarity** kullanarak TÃ¼rkÃ§e ve Ä°ngilizce kurumsal terimler arasÄ±ndaki anlamsal benzerliÄŸi ne kadar iyi yakaladÄ±ÄŸÄ±nÄ± Ã¶lÃ§mektedir. Test sistemi Ã¶zellikle **TÃ¼rkÃ§e-Ä°ngilizce Ã§eviri doÄŸruluÄŸuna** odaklanmaktadÄ±r.

### Temel AmaÃ§lar:
- âœ… 8 farklÄ± embedding modelinin karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±  
- âœ… Kurumsal terminoloji iÃ§in en uygun modelin belirlenmesi
- âœ… **TÃ¼rkÃ§e-Ä°ngilizce Ã§eviri kalitesinin Ã¶ncelikli deÄŸerlendirilmesi**
- âœ… Model performanslarÄ±nÄ±n kategorik analizi
- âœ… **MantÄ±klÄ± deÄŸerlendirme kriterleri** (sadece Ã§eviri testleri sayÄ±lÄ±r)

---

## ğŸ¤– Test Edilen Modeller

| Model AdÄ± | TÃ¼r | Ã–zellikler | Model Boyutu | Ã–ne Ã‡Ä±kan Ã–zellik |
|-----------|-----|------------|--------------|-------------------|
| **Alibaba GTE** | Sentence Transformer | Ã‡ok dilli, genel amaÃ§lÄ± | ~560MB | GÃ¼Ã§lÃ¼ Ã§ok dilli destek |
| **E5 Multilingual** | Transformer | Microsoft, Ã§ok dilli | ~1.1GB | Akademik/profesyonel |
| **E5 Small** | Transformer | Hafif versiyon | ~470MB | HÄ±z ve verimlilik |
| **DistilUSE v1** | Sentence Transformer | Distilled model | ~510MB | HÄ±zlÄ± iÅŸlem |
| **Nomic AI** | Transformer | Mixture of Experts | ~1.4GB | KarmaÅŸÄ±k analiz |
| **LaBSE** | Sentence Transformer | Google, dil agnostik | ~470MB | 109 dil desteÄŸi |
| **Trendyol** | Sentence Transformer | E-ticaret, TÃ¼rkÃ§e odaklÄ± | ~470MB | **TÃ¼rkÃ§e optimize** |
| **Snowflake Arctic** | Sentence Transformer | Yeni nesil, prompt destekli | ~560MB | Modern mimari |

### ğŸ¯ Ã–nemli Not:
Sistem, model performansÄ±nÄ± deÄŸerlendirirken **sadece TÃ¼rkÃ§e-Ä°ngilizce Ã§eviri testlerini (ilk 24 test)** dikkate alÄ±r. ZÄ±t anlamlar ve ilgisiz kelimeler sadece model davranÄ±ÅŸÄ±nÄ± anlamak iÃ§in kullanÄ±lÄ±r.

---

## ğŸ”¬ Test Metodolojisi

### DeÄŸerlendirme Sistemi:
- **Ana Metrik**: Sadece **TÃ¼rkÃ§e-Ä°ngilizce Ã§eviri testleri** (24/60 test) deÄŸerlendirmeye dahil
- **Kazanan Belirleme**: Her testte en yÃ¼ksek cosine similarity skorunu alan model 1 puan alÄ±r
- **Final SÄ±ralama**: X/24 test kazanan model formatÄ±nda gÃ¶sterilir
- **Kategorik Analiz**: TÃ¼m kategorilerde ortalama performans ayrÄ±ca hesaplanÄ±r

### Benzerlik Hesaplama:
- **Cosine Similarity** algoritmasÄ± kullanÄ±lmÄ±ÅŸtÄ±r
- Her kelime Ã§ifti iÃ§in embedding vektÃ¶rleri oluÅŸturulur
- VektÃ¶rler arasÄ±ndaki aÃ§Ä±nÄ±n kosinÃ¼sÃ¼ hesaplanÄ±r (-1 ile +1 arasÄ±)
- Pozitif deÄŸerler benzerlik, negatif deÄŸerler farklÄ±lÄ±k gÃ¶sterir

### Test Kategorileri:

#### 1. ğŸ¯ **TÃ¼rkÃ§e-Ä°ngilizce Ã‡eviriler** (SIRALAMADA ETKÄ°LÄ°)
**Bu testler model sÄ±ralamasÄ±nÄ± belirler - YÃ¼ksek benzerlik beklenir (>0.8)**
- mali rapor â†” financial report
- vergi â†” tax  
- fatura â†” invoice
- sÃ¶zleÅŸme â†” contract
- ÅŸirket â†” company
- yÃ¶netim kurulu â†” board of directors
- hisse â†” stock
- bilanÃ§o â†” balance sheet
- muhasebe â†” accounting
- bÃ¼tÃ§e â†” budget
- nakit akÄ±ÅŸÄ± â†” cash flow
- karlÄ±lÄ±k â†” profitability
- satÄ±ÅŸ â†” sales
- pazarlama â†” marketing
- insan kaynaklarÄ± â†” human resources
- iÅŸe alÄ±m â†” recruitment
- maaÅŸ bordrosu â†” payroll
- performans deÄŸerlendirmesi â†” performance evaluation
- operasyon â†” operation
- proje yÃ¶netimi â†” project management
- risk analizi â†” risk analysis
- iÅŸ planÄ± â†” business plan
- strateji â†” strategy
- yatÄ±rÄ±m â†” investment

#### 2. ğŸ“Š **Benzer Anlamlar** (Sadece analiz iÃ§in)
YakÄ±n anlamlÄ± TÃ¼rkÃ§e terimler - Orta benzerlik beklenir (0.5-0.7):
- fatura â†” Ã¶deme belgesi
- hisse â†” pay
- yÃ¶netici â†” mÃ¼dÃ¼r  
- gider â†” harcama
- karlÄ±lÄ±k â†” getiri
- personel â†” Ã§alÄ±ÅŸan
- mÃ¼ÅŸteri â†” istemci
- satÄ±ÅŸ â†” ticaret
- toplantÄ± â†” gÃ¶rÃ¼ÅŸme
- rapor â†” dokÃ¼man
- analiz â†” inceleme
- planlama â†” organizasyon

#### 3. ğŸ”„ **ZÄ±t Anlamlar** (Sadece analiz iÃ§in)
KarÅŸÄ±t anlamlÄ± finansal terimler - DÃ¼ÅŸÃ¼k benzerlik beklenir (<0.3):
- gelir â†” gider
- kÃ¢r â†” zarar
- aktif â†” pasif
- alacak â†” borÃ§
- satÄ±ÅŸ â†” satÄ±n alma
- artÄ±ÅŸ â†” azalÄ±ÅŸ
- baÅŸarÄ± â†” baÅŸarÄ±sÄ±zlÄ±k
- verimlilik â†” verimsizlik
- geniÅŸleme â†” kÃ¼Ã§Ã¼lme
- yatÄ±rÄ±m â†” geri Ã§ekme
- yÃ¼kselme â†” dÃ¼ÅŸÃ¼ÅŸ
- kazanÃ§ â†” kayÄ±p

#### 4. âŒ **Ä°lgisiz Kelimeler** (Sadece analiz iÃ§in)
HiÃ§bir anlam iliÅŸkisi olmayan terimler - Ã‡ok dÃ¼ÅŸÃ¼k benzerlik (<0.2):
- bilanÃ§o â†” Ã§alÄ±ÅŸan motivasyonu
- vergi â†” ÅŸirket logosu
- sÃ¶zleÅŸme â†” mÃ¼zik listesi
- yÃ¶netim kurulu â†” hava durumu raporu
- muhasebe â†” spor mÃ¼sabakasÄ±
- mali rapor â†” yemek tarifi
- nakit akÄ±ÅŸÄ± â†” film eleÅŸtirisi
- karlÄ±lÄ±k â†” bahÃ§e tasarÄ±mÄ±
- proje yÃ¶netimi â†” moda trendi
- risk analizi â†” seyahat rehberi
- performans deÄŸerlendirmesi â†” mÃ¼ze koleksiyonu
- insan kaynaklarÄ± â†” uzay araÅŸtÄ±rmasÄ±

---

## âš™ï¸ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma TalimatlarÄ±

### Gerekli KÃ¼tÃ¼phaneler:
```bash
pip install sentence-transformers
pip install transformers  
pip install torch
pip install einops  # Kritik baÄŸÄ±mlÄ±lÄ±k!
```

### Test Ã‡alÄ±ÅŸtÄ±rma:
```bash
cd LLM_Cosine_Similarity
python Models_Test.py
```

### Test SÃ¼recinin AÅŸamalarÄ±:
1. **Model YÃ¼kleme**: 8 model RAM'e yÃ¼klenir (~3-6 dakika, ~8GB RAM gerekli)
2. **Test BaÅŸlatma**: 60 kelime Ã§ifti sÄ±rayla test edilir  
3. **Benzerlik Hesaplama**: Her model iÃ§in cosine similarity hesaplanÄ±r
4. **SÄ±ralama**: Sadece TÃ¼rkÃ§e-Ä°ngilizce Ã§eviri testleri deÄŸerlendirilir
5. **Rapor OluÅŸturma**: Kategorik analiz ve model sÄ±ralamasÄ± gÃ¶sterilir

### Ã‡Ä±ktÄ± FormatÄ±:
```
ğŸ”§ Modeller yÃ¼kleniyor...
Bu iÅŸlem biraz zaman alabilir...

KAPSAMLI MODEL TEST SÄ°STEMÄ°
================================================================================

 Test  1/60: 'mali rapor' â†” 'financial report'  
------------------------------------------------------------
     Alibaba GTE: 0.8543
  E5 Multilingual: 0.8721  
         E5 Small: 0.8432
     DistilUSE v1: 0.7865
         Nomic AI: 0.8234
           LaBSE: 0.8876
        Trendyol: 0.8654
 Snowflake Arctic: 0.8798

[...diÄŸer testler...]

================================================================================
ğŸ“Š GENEL SONUÃ‡LAR VE ANALÄ°Z
================================================================================

ğŸ† MODEL ORTALAMA PERFORMANSLARI:
--------------------------------------------------

ğŸ¥Š TÃœRKÃ‡E-Ä°NGÄ°LÄ°ZCE Ã‡EVÄ°RÄ° BAÅARI SONUÃ‡LARI:
---------------------------------------------
  1. LaBSE: 18/24 test kazandÄ±
  2. Snowflake Arctic: 4/24 test kazandÄ±  
  3. Trendyol: 2/24 test kazandÄ±
  [...]
```

### ğŸ¯ Ä°deal Model Ã–zellikleri:
âœ… **TÃ¼rkÃ§e-Ä°ngilizce Ã§evirilerde yÃ¼ksek skor** (>0.80) - Ana kriter  
âœ… **ZÄ±t anlamlarda dÃ¼ÅŸÃ¼k skor** (<0.30) - Model gÃ¼venilirliÄŸi  
âœ… **Ä°lgisiz kelimelerde Ã§ok dÃ¼ÅŸÃ¼k skor** (<0.20) - YanlÄ±ÅŸ pozitif Ã¶nleme  
âœ… **Benzer anlamlarda orta dÃ¼zey skor** (0.50-0.70) - Anlam ayrÄ±mÄ±  
âœ… **TutarlÄ± performans** - Kategoriler arasÄ± dengeli davranÄ±ÅŸ

### âš ï¸ DeÄŸerlendirme Kriterleri:
- **Model sÄ±ralamasÄ±**: Sadece TÃ¼rkÃ§e-Ä°ngilizce Ã§eviri testlerinde kazanÄ±lan test sayÄ±sÄ±na gÃ¶re
- **Kategorik analiz**: TÃ¼m testlerin ortalamasÄ± (model davranÄ±ÅŸÄ±nÄ± anlamak iÃ§in)
- **BaÅŸarÄ± Ã¶lÃ§Ã¼tÃ¼**: X/24 test kazandÄ± formatÄ±nda gÃ¶sterilir  

---

## ğŸ”§ Teknik Detaylar

### Model Mimarileri ve BoyutlarÄ±:
| Model | Mimari | Embedding Boyutu | Tokenizasyon | Ã–zel Ã–zellik |
|-------|--------|------------------|--------------|--------------|
| Alibaba GTE | BERT-like | 768 | WordPiece | Ã‡ok dilli optimize |
| E5 Multilingual | BERT-like | 768 | WordPiece | "query: " prefix |
| E5 Small | BERT-like | 384 | WordPiece | "query: " prefix |
| DistilUSE | DistilBERT | 512 | WordPiece | SÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ |
| Nomic AI | MoE | 768 | Custom | Mixture of Experts |
| LaBSE | BERT-like | 768 | SentencePiece | 109 dil desteÄŸi |
| Trendyol | BERT-like | 768 | WordPiece | E-ticaret odaklÄ± |
| Snowflake Arctic | BERT-like | 1024 | WordPiece | Prompt desteÄŸi |

### Ã–zel Test FonksiyonlarÄ±:

#### Sentence Transformer Modelleri:
```python
def test_sentence_transformer_model(model, word1, word2):
    emb1 = model.encode(word1, convert_to_tensor=True)
    emb2 = model.encode(word2, convert_to_tensor=True)
    return util.pytorch_cos_sim(emb1, emb2).item()
```

#### Snowflake Arctic (Prompt Destekli):
```python
def test_snowflake_model(model, word1, word2):
    query_emb = model.encode([word1], prompt_name="query", convert_to_tensor=True)
    doc_emb = model.encode([word2], convert_to_tensor=True)
    return util.pytorch_cos_sim(query_emb, doc_emb).item()
```

#### Transformer Modelleri (E5, Nomic AI):
```python
def test_transformers_model(model, tokenizer, word1, word2, prefix=""):
    texts = [f"{prefix}{word1}", f"{prefix}{word2}"]
    batch = tokenizer(texts, max_length=512, padding=True, 
                     truncation=True, return_tensors='pt')
    
    with torch.no_grad():
        outputs = model(**batch)
    
    embeddings = average_pool(outputs.last_hidden_state, batch['attention_mask'])
    embeddings = F.normalize(embeddings, p=2, dim=1)
    
    return (embeddings[0] @ embeddings[1].T).item()
```

#### Average Pooling Fonksiyonu:
```python
def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:
    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)
    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]
```

---

## ğŸ“Š SonuÃ§ Analizi ve Yorumlama

Bu bÃ¶lÃ¼mde, test sonuÃ§larÄ±nÄ±n nasÄ±l deÄŸerlendirileceÄŸi ve modellerin farklÄ± kullanÄ±m senaryolarÄ±na gÃ¶re nasÄ±l seÃ§ileceÄŸi aÃ§Ä±klanmaktadÄ±r.

### ğŸ“ˆ Rapor Ã‡Ä±ktÄ±larÄ±:

#### 1. ğŸ† **Model Ortalama PerformanslarÄ±**
- **Kapsam**: TÃ¼m 60 testin genel ortalamasÄ±
- **AmaÃ§**: Modellerin genel benzerlik yakalamasÄ± yeteneÄŸini gÃ¶sterir
- **Not**: Bu ortalama **sÄ±ralama iÃ§in kullanÄ±lmaz** (zÄ±t anlamlar skorlarÄ± yÃ¼kseltebilir)

#### 2. ğŸ“ˆ **Kategori Analizi**
- **TÃ¼rkÃ§e-Ä°ngilizce Ã‡eviriler**: En Ã¶nemli kategori, yÃ¼ksek skor beklenir
- **Benzer Anlamlar**: Model nÃ¼anslarÄ± yakalama yeteneÄŸi
- **ZÄ±t Anlamlar**: Modelin karÄ±ÅŸmasÄ±nÄ± engelleyebilme
- **Ä°lgisiz Kelimeler**: YanlÄ±ÅŸ pozitif Ã¶nleme kabiliyeti

#### 3. ğŸ¥Š **TÃ¼rkÃ§e-Ä°ngilizce Ã‡eviri BaÅŸarÄ± SonuÃ§larÄ±** 
- **Ana Metrik**: Model sÄ±ralamasÄ± sadece buna dayanÄ±r
- **Format**: "X/24 test kazandÄ±" ÅŸeklinde gÃ¶sterilir
- **MantÄ±k**: Her testte en yÃ¼ksek benzerlik skoru alan model 1 puan kazanÄ±r

#### 4. ğŸ¯ **En YÃ¼ksek/DÃ¼ÅŸÃ¼k Skorlar**
- Dikkat Ã§eken anormal sonuÃ§larÄ±n belirlenmesi
- Model davranÄ±ÅŸlarÄ±nÄ±n detaylÄ± analizi

### ğŸ¯ Model SeÃ§im Kriterleri:

#### ğŸ† **Genel AmaÃ§lÄ± KullanÄ±m:**
- **LaBSE**: 
  - âœ… 109 dil desteÄŸi, Google'Ä±n Ã§ok dilli modeli
  - âœ… Dengeli performans, gÃ¼venilir sonuÃ§lar
  - âœ… Kurumsal projeler iÃ§in ideal
- **Alibaba GTE**: 
  - âœ… Ã‡ok dilli desteÄŸi gÃ¼Ã§lÃ¼
  - âœ… Orta boyutlu, makul kaynak kullanÄ±mÄ±
  - âœ… Genel amaÃ§lÄ± projeler iÃ§in uygun
- **Snowflake Arctic**: 
  - âœ… En yeni nesil embedding modeli
  - âœ… Prompt destekli Ã¶zellikler
  - âœ… Modern AI uygulamalarÄ± iÃ§in optimize

#### ğŸ‡¹ğŸ‡· **TÃ¼rkÃ§e OdaklÄ± Projeler:**
- **Trendyol**: 
  - âœ… TÃ¼rkÃ§e e-ticaret verisi ile eÄŸitilmiÅŸ
  - âœ… TÃ¼rkÃ§e kurumsal terimler iÃ§in optimize
  - âœ… Yerel ÅŸirketlerin projelerine uygun
- **LaBSE**: 
  - âœ… TÃ¼rkÃ§e dahil 109 dil desteÄŸi
  - âœ… Ã‡ok dilli projeler iÃ§in ideal
  - âœ… Google'Ä±n dil agnostik yaklaÅŸÄ±mÄ±

#### âš¡ **Performans OdaklÄ±:**
- **E5 Small**: 
  - âœ… En hafif model (~470MB)
  - âœ… HÄ±zlÄ± iÅŸlem, dÃ¼ÅŸÃ¼k kaynak tÃ¼ketimi
  - âœ… Mobil uygulamalar iÃ§in uygun
- **DistilUSE v1**: 
  - âœ… Distilled (sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ) mimari
  - âœ… Ä°yi performans/boyut oranÄ±
  - âœ… Edge computing iÃ§in optimize

#### ğŸ”¬ **AraÅŸtÄ±rma ve GeliÅŸtirme:**
- **Nomic AI**: 
  - âœ… Mixture of Experts mimarisi
  - âœ… KarmaÅŸÄ±k anlamsal analizler iÃ§in gÃ¼Ã§lÃ¼
  - âœ… Deneysel projeler ve araÅŸtÄ±rmalar iÃ§in
- **E5 Multilingual**: 
  - âœ… Microsoft'un akademik standardÄ±
  - âœ… Peer-reviewed araÅŸtÄ±rmalarda kullanÄ±lÄ±r
  - âœ… Bilimsel Ã§alÄ±ÅŸmalar iÃ§in referans model

### âš ï¸ Ã–nemli DeÄŸerlendirme NotlarÄ±:

#### ğŸ¯ **SÄ±ralama MantÄ±ÄŸÄ±:**
- **âœ… DoÄŸru**: Sadece TÃ¼rkÃ§e-Ä°ngilizce Ã§eviri testleri sayÄ±lÄ±r
- **âŒ YanlÄ±ÅŸ**: TÃ¼m testlerin ortalamasÄ±na bakmak
- **Sebep**: ZÄ±t anlamlar ve ilgisiz kelimeler farklÄ± amaÃ§lara hizmet eder

#### ğŸ“Š **Kategorik Analiz AmacÄ±:**
- Model davranÄ±ÅŸÄ±nÄ± **anlamak** iÃ§in kullanÄ±lÄ±r
- SÄ±ralama iÃ§in **kullanÄ±lmaz**
- Hangi durumda hangi modelin gÃ¼Ã§lÃ¼/zayÄ±f olduÄŸunu gÃ¶sterir

#### ğŸ” **YÃ¼ksek Ortalama TuzaÄŸÄ±:**
- YÃ¼ksek genel ortalama â‰  Ä°yi Ã§eviri performansÄ±
- ZÄ±t anlamlar kategorisinde yÃ¼ksek skor kÃ¶tÃ¼ bir iÅŸaret olabilir
- Ä°lgisiz kelimeler kategorisinde yÃ¼ksek skor problem gÃ¶sterir

#### ğŸ… **MÃ¼kemmel Performans:**
- **24/24 test kazanan model** mutlaka en iyidir
- BÃ¶yle bir model tÃ¼m Ã§eviri testlerinde birinci gelmiÅŸtir
- GerÃ§ek projeler iÃ§in en gÃ¼venilir seÃ§imdir

---

## ğŸ¯ Proje Sonucu ve DeÄŸerlendirme

Bu analiz sistemi, **TÃ¼rkÃ§e-Ä°ngilizce kurumsal terminoloji** iÃ§in en uygun embedding modelini bilimsel yÃ¶ntemlerle belirlemeyi amaÃ§lamaktadÄ±r.

### âœ… BaÅŸarÄ±lan Hedefler:
- 8 farklÄ± embedding modelinin kapsamlÄ± karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±
- MantÄ±klÄ± deÄŸerlendirme kriterlerinin geliÅŸtirilmesi  
- Kategorik analiz ile model davranÄ±ÅŸlarÄ±nÄ±n anlaÅŸÄ±lmasÄ±
- TÃ¼rkÃ§e-Ä°ngilizce Ã§eviri odaklÄ± sÄ±ralama sistemi
- Teknik detaylarÄ± iÃ§eren kapsamlÄ± dokÃ¼mantasyon
- 60 test verisi ile geniÅŸletilmiÅŸ kapsamlÄ± analiz

### ğŸ”® Gelecek GeliÅŸtirmeler:
- Daha fazla kurumsal terminoloji eklenmesi
- Domain-specific model fine-tuning
- Ã‡oklu metrik deÄŸerlendirme (BLEU, ROUGE vb.)
- Batch processing optimizasyonlarÄ±  
- Web arayÃ¼zÃ¼ geliÅŸtirilmesi
- SektÃ¶rel Ã¶zelleÅŸtirmeler (finans, teknoloji, saÄŸlÄ±k vb.)

### ğŸ“ˆ Beklenen SonuÃ§lar:
Test tamamlandÄ±ktan sonra aÅŸaÄŸÄ±daki formatda sonuÃ§lar elde edilecek:

```
ğŸ¥Š TÃœRKÃ‡E-Ä°NGÄ°LÄ°ZCE Ã‡EVÄ°RÄ° BAÅARI SONUÃ‡LARI:
---------------------------------------------
  1. [Model AdÄ±]: X/24 test kazandÄ±
  2. [Model AdÄ±]: Y/24 test kazandÄ±
  3. [Model AdÄ±]: Z/24 test kazandÄ±
  ...
```

### ğŸš€ KullanÄ±m Ã–nerileri:
- **Proje baÅŸlangÄ±cÄ±nda**: Model seÃ§imi iÃ§in test Ã§alÄ±ÅŸtÄ±rÄ±n
- **Performans analizi**: Kategorik sonuÃ§larÄ± inceleyin  
- **Optimizasyon**: Sadece Ã§eviri testlerindeki baÅŸarÄ±ya odaklanÄ±n
- **Model deÄŸiÅŸtirme**: Yeni modeller ekleyerek karÅŸÄ±laÅŸtÄ±rÄ±n
- **A/B Testing**: FarklÄ± modelleri gerÃ§ek verilerle karÅŸÄ±laÅŸtÄ±rÄ±n

---

## ğŸ“ Destek ve Ä°letiÅŸim

**ğŸ“… Rapor Tarihi**: Temmuz 2025  
**ğŸ”¬ Test Versiyonu**: v2.1 (Cleaned & Optimized)  
**ğŸ‘¨â€ğŸ’» GeliÅŸtirici**: Ãœmit AnÄ±k  
**ğŸ¢ Proje**: BimserStajProje_1  
**âš¡ Son GÃ¼ncelleme**: Rapor tamamen yeniden dÃ¼zenlendi

### ğŸ“ Dosya YapÄ±sÄ±:
```
LLM_Cosine_Similarity/
â”œâ”€â”€ Models_Test.py          # Ana test sistemi (60 test)
â”œâ”€â”€ SIMILARITY_REPORT.md    # Bu rapor
â””â”€â”€ [Test sonuÃ§larÄ±]        # Otomatik oluÅŸturulacak
```

### ğŸ–¥ï¸ Sistem Gereksinimleri:
- **Python**: 3.8+
- **RAM**: ~8GB (model yÃ¼kleme iÃ§in)
- **Disk**: ~10GB (model indirme iÃ§in)
- **GPU**: CUDA destekli GPU (Ã¶nerilen, opsiyonel)
- **Ä°nternet**: Model indirme iÃ§in gerekli

### âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§:
```bash
# KlasÃ¶re geÃ§iÅŸ
cd LLM_Cosine_Similarity

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install sentence-transformers transformers torch einops

# Testi Ã§alÄ±ÅŸtÄ±r
python Models_Test.py
```

### ğŸ”§ Sorun Giderme:
- **ModuleNotFoundError**: `pip install` komutlarÄ±nÄ± tekrar Ã§alÄ±ÅŸtÄ±rÄ±n
- **CUDA Error**: CPU modunda Ã§alÄ±ÅŸtÄ±rmayÄ± deneyin
- **Memory Error**: Daha az model ile test edin
- **Network Error**: Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin
