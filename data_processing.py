import pickle

import pandas as pd
import pytorch_lightning as pl
import requests
import torch
import torch.nn.functional as F
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from torch import nn
from torch.utils.data import DataLoader, TensorDataset


def set_options():
    pd.set_option("display.max_columns", None)
    pd.set_option("display.width", None)
    pd.set_option("display.max_colwidth", None)


def get_data_from_api():
    try:
        response = requests.get("http://localhost:8000/data")
        if response.status_code == 200:
            data = response.json().get("data", [])
            print(f"{len(data)} kayÄ±t baÅŸarÄ±yla alÄ±ndÄ±")
            return pd.DataFrame(data)
        else:
            print(f"API Ã§aÄŸrÄ±sÄ± baÅŸarÄ±sÄ±z: {response.status_code}")
            return pd.DataFrame()
    except Exception as e:
        print(f"API Ã§aÄŸrÄ±sÄ± sÄ±rasÄ±nda hata: {e}")
        return pd.DataFrame()


class SimpleModel(pl.LightningModule):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(4, 16),
            nn.ReLU(),
            nn.Linear(16, 8),
            nn.ReLU(),
            nn.Linear(8, 1),
            nn.Sigmoid(),
        )
        self.loss_fn = nn.BCELoss()

    def forward(self, x):
        return self.model(x)

    def training_step(self, batch):
        x, y = batch
        y_hat = self(x)
        loss = F.mse_loss(y_hat, y.unsqueeze(1))
        self.log("train_loss", loss)
        return loss

    def validation_step(self, batch):
        x, y = batch
        y_hat = self(x)
        loss = F.mse_loss(y_hat, y.unsqueeze(1))

        preds = (y_hat > 0.5).float()
        acc = (preds.squeeze() == y).float().mean()

        self.log("val_loss", loss)
        self.log("val_acc", acc)

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=0.01)


def train_simple_model(df):
    features = ["age", "complaint_count", "year_total", "years_with_company"]
    X = df[features].values

    le = LabelEncoder()
    y = le.fit_transform(df["customer_loyalty"])

    scaler = StandardScaler()
    X = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    X_train = torch.FloatTensor(X_train)
    X_test = torch.FloatTensor(X_test)
    y_train = torch.FloatTensor(y_train)
    y_test = torch.FloatTensor(y_test)

    train_dataset = TensorDataset(X_train, y_train)
    test_dataset = TensorDataset(X_test, y_test)
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=16)

    model = SimpleModel()
    trainer = pl.Trainer(max_epochs=20, enable_progress_bar=True, log_every_n_steps=5)

    trainer.fit(model, train_loader, test_loader)
    model.eval()

    with torch.no_grad():
        test_preds = model(X_test)
        test_acc = ((test_preds > 0.5).float().squeeze() == y_test).float().mean()
        print(f"\nğŸ¯ Test Accuracy: {test_acc:.4f}")

    model_data = {
        "model_state": model.state_dict(),
        "scaler": scaler,
        "label_encoder": le,
        "features": features,
        "model_class": SimpleModel,
    }

    with open("complete_model.pkl", "wb") as f:
        pickle.dump(model_data, f)

    print("ğŸ’¾ Tam model kaydedildi: complete_model.pkl")

    return model


def predict_new_customer(age, complaint, year_total, years_company):
    try:
        with open("complete_model.pkl", "rb") as f:
            model_data = pickle.load(f)

        model = model_data["model_class"]()
        model.load_state_dict(model_data["model_state"])
        model.eval()

        scaler = model_data["scaler"]
        le = model_data["label_encoder"]

        data = [[age, complaint, year_total, years_company]]
        data_scaled = scaler.transform(data)
        data_tensor = torch.FloatTensor(data_scaled)

        with torch.no_grad():
            prob = model(data_tensor).item()
            pred = 1 if prob > 0.5 else 0
            label = le.inverse_transform([pred])[0]

        print(f"\nğŸ”® TAHMÄ°N:")
        print(f"   MÃ¼ÅŸteri: {age}yaÅŸ, {complaint}ÅŸikayet, {year_total}â‚º, {years_company}yÄ±l")
        print(f"   SonuÃ§: {label}")

        return label

    except Exception as e:
        print(f"âŒ Tahmin hatasÄ±: {e}")
        return None

#Model eÄŸitimi ve tahmin fonksiyonlarÄ±
"""if __name__ == "__main__":
    set_options()
    print("ğŸš€ MÃ¼ÅŸteri Sadakat Modeli EÄŸitimi")
    print("=" * 50)

    # 1. Veri al
    df = get_data_from_api()

    if not df.empty:
        print("\nğŸ“‹ Veri Ã¶nizlemesi:")
        print(df.head())

        print(f"\nğŸ“Š Veri Ã¶zeti:")
        print(f"   Toplam kayÄ±t: {len(df)}")
        print(f"   SadÄ±k mÃ¼ÅŸteri: {len(df[df['customer_loyalty']=='Sadik'])}")
        print(f"   Terk edebilir: {len(df[df['customer_loyalty']=='Terk Edebilir'])}")

        print("\nğŸ¤– Model eÄŸitimi baÅŸlÄ±yor...")
        model = train_simple_model(df)

        if model:
            print("\nâœ… Model eÄŸitimi tamamlandÄ±!")

            # 3. Ã–rnek tahminler
            print("\nğŸ§ª Ã–RNEK TAHMÄ°NLER:")
            predict_new_customer(30, 0, 120000, 4)  # GenÃ§, sadÄ±k beklenen
            predict_new_customer(55, 5, 60000, 1)  # YaÅŸlÄ±, terk edebilir
            predict_new_customer(40, 2, 90000, 3)  # Ortalama

        else:
            print("\nâŒ Model eÄŸitimi baÅŸarÄ±sÄ±z!")
    else:
        print("\nâŒ Veri alÄ±namadÄ±!")
        print("ğŸ’¡ Ã‡Ã¶zÃ¼m: API sunucusunu baÅŸlatÄ±n: python api.py")"""
